---
title: ずっと気になっていたDeepSeekMathについてまとめてみた
tags:
  - 強化学習
  - AI
  - LLM
  - DeepSeekMath
private: false
updated_at: '2025-02-14T08:19:58+09:00'
id: 4858ec41430f77dcb582
organization_url_name: null
slide: false
ignorePublish: false
---
# Claudeによる本記事の要約

DeepSeekMathは、Common Crawlから収集した1200億以上の数学トークンを使用し、数学的推論に特化して開発されたAIモデル。GRPOという効率的な学習方式を採用し、外部ツールに頼ることなく数学オリンピックレベルの問題を50%以上の正答率で解決できる。GPT-4やGemini-Ultraと同等の性能を持つが、リソース要求が高いという課題がある。​​​​​​​​​​​​​​​​

# 「DeepSeekMath」の概要
DeepSeekMathとは中国のAI企業であるDeepSeek（深度求索）によって開発された「数学的な推論能力に特化したAIモデル」です。
主に”数学分野でのLLM”として、活用が期待されています。

下でも共有していますが、私はKaggleサーフィンをしているときにこのモデルを見つけました。このモデルをうまく使えば、数学オリンピック並の問題を50％以上の正答率で答えを出せるのですね。
これがどれほどすごいのかということはわかりにくいかもしれませんし、私も100％理解しているわけでありませんが、ただみんな大好きChatGPTに高度な数学問題はまだまだ難しいのです。

https://github.com/deepseek-ai/DeepSeek-Math

上記Githubや論文を引用し、わかりやすい言葉でDeepSeekMathを解説していきます。



# 特徴①データセット：Common Crawl

まずDeepSeekMathの訓練には、Common Crawlから得られた「1200億以上の数学トークン」が使用されています。このデータによって、ただ数字や方程式だけでなく、数学の言語の様々な形式をAIに教えることが可能となり、高度な数学問題を解決することができるようになっているのです。

Common Crawlとは、ウェブ上の情報を広範に収集したオープンデータセットで、このデータは非営利団体のプロジェクトによってオープンに提供されています。
DSMだけでなく、様々なLLMや派生したモデルがCommon Crawlを使っています。

https://commoncrawl.org/get-started

# 特徴②学習モデル：Generalized Reinforcement Learning Optimization (GRPO) 

DeepSeekMathをここまで強いモデルにした要因として、「Generalized Reinforcement Learning Optimization (GRPO)」が挙げられます。
簡単に言うと、強化学習の1つのアプローチ（PPOアルゴリズム）を数学の知識に特化させ、さらにバージョンアップさせたものです。
例えば、複雑な微積分の問題が与えられた場合、GRPOによりDeepSeekMathは必要な計算を行うだけでなく、なぜ特定のアプローチが他よりも優れているのかを理解することができます。

またGRPOのすごい点として、リソース効率が良いことです。AIの開発においてリソース効率は重要な課題であり、どのモデルも膨大な計算能力とデータが必要でした。ただGRPOは、学習プロセスを効率化し、必要な試行錯誤を減らすことで、訓練に必要なリソースを削減できています。この効率化により、高度なAIモデルがより利用可能で持続可能となり、新たなイノベーションと応用の可能性が広がりました。


↓PPOとGRPOのモデルとしての違い
![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/680f1b6e-33f3-8b54-e026-03d6f52643e3.png)

通常のPPOと違うのは、数学に特化した点と価値関数を実装するための「バリューモデル」を使わずリソースを節約している点です。


PPOがよくわからないという方はこちらを参考にしてください。

https://daily-life-ai.com/440/


# どれくらいすごいのか？

下は24年1月時点の情報ですが、1番わかりやすい数学(競技レベル)ベンチマークでは、外部ツールや投票技術に頼ることなくGPT4やGemini-Ultraとほぼ同等のスコアを記録しています。


![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/9d90f24e-44e6-f2ce-33ac-4c034563f7d3.png)

「じゃあGPTやGeminiでいいじゃん！」という声が聞こえてきそうですが、あくまでモデルの中で理解しているか、完結しているかどうかが大事なんだと思います。

例えば「三角形の内角の総和は？」という質問の場合、どのモデルも「180度」と解答できますが、導いた過程が異なります。
GPTなどの場合ほかの引用に頼り答えを導き出しており、決してモデル自体が「三角形の内角の総和は180度」と導いているわけではありません。そのため、間違っている場合もあったり、過程を示すことができなかったりします。

もしかしたらDSMを評価できる、もっと適したベンチマークがあるのかもしれませんね。
ここで使われているMath benchmarkについてはこちら

https://github.com/hendrycks/math/


Githubにはその他のベンチマークもあります。

https://github.com/deepseek-ai/DeepSeek-Math/tree/main


# Kaggleで使われている例

AIMOというAIを用いた数学オリンピックのコンペです。
DeepSeekMathを使用したコードがゴールドを獲得しています。

https://www.kaggle.com/code/olyatsimboy/aimo-zero-shot-sc-mmos-deepseekmath

https://www.kaggle.com/code/alexandervc/deepseekmath-solution-explained-for-beginners#Main-code

# 実際にDeepSeekMathを使ってみた！と言いたかったが…。

実際にGoogle Colabで使おうとしたのですが…。
RAMのメモリが足りず、無料で使用しているGoogleColab上では機能が発揮できませんでした。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/3780099/5eab94a2-fd7e-7101-1c1b-e0052b41b2c4.png)

ライブラリやモデルを随時変更して色々と粘ったのですが、一旦今回は諦めます…。
失敗しているのですが、コード例として、記載しておきます。

```ruby:python.rb
# GitHubリポジトリからDeepSeekMathをクローン
!git clone https://github.com/deepseek-ai/DeepSeek-Math.git
%cd DeepSeek-Math

# 必要なライブラリのインストール
!pip install transformers torch numpy

# モデルのパス
model_path = "deepseek-ai/deepseek-math-7b-base"  # Hugging Faceでモデルを選択

# トークナイザーとモデルの読み込み
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path)

# 数学の問題を解かせる
input_text = "Solve: x^2 - 5x + 6 = 0"
inputs = tokenizer(input_text, return_tensors="pt")
outputs = model.generate(**inputs)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

# 今後期待できること


個人的に上手く使うことはできなかったのですが、DeepSeekMathにはとても期待しています。
これから数学特化という独自性を追求しスコアをさらに上げ、またアプリ開発や現存のLLMに組み込みされると、GPTやGeminiに並ぶ1つのLLMが完成するのではないでしょうか？
「言語処理できる電卓」みたいな…。

建築系や金融系の複雑な計算を行なっている業務はもちろん、
経理関係や目標設定・予測など、どの会社も行なっている定常業務にも役立てられるかもしれません。


ただ懸念として、GPTの数学処理も日々レベルアップしています。
昨年までは「数学計算が苦手」と言われていたGPTも今はほとんど改善されています。
↓参考

https://www.nii.ac.jp/event/upload/20230707-03_Minato.pdf


「GPTと差別化するには？」という観点は必須のように思えます。


# 引用・リポジトリ

- Github

https://github.com/deepseek-ai/DeepSeek-Math/tree/main

- Huggingface

https://huggingface.co/deepseek-ai

- 論文

https://arxiv.org/abs/2402.03300

