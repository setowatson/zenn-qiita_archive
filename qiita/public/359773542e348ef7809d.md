---
title: 【kaggle】画像認識に強いVanilla Classificationの実装
tags:
  - 画像認識
  - Kaggle
  - ディープフェイク
  - vanillaClassification
private: false
updated_at: '2025-03-04T09:15:32+09:00'
id: 359773542e348ef7809d
organization_url_name: null
slide: false
ignorePublish: false
---
# Kaggleコンペで学ぶVanilla Classification



## コンペ概要「Can You Tell the Difference?」

https://www.kaggle.com/competitions/detect-ai-vs-human-generated-images/overview


近年、AIによるコンテンツ生成技術が急速に発展し、リアルとAI生成の違いを見分けることがますます困難になっています。本コンペでは、**AI生成画像と人間が作成した画像を分類する機械学習モデルの開発**が求められています。

### 背景
- **ディープフェイク技術の進化**により、画像・動画・音声などの生成精度が向上。
- **メディアの信頼性・セキュリティ・倫理的課題**が浮上し、AI生成コンテンツを識別する技術が重要に。
- **誤情報の拡散や信頼性の低下を防ぐ**ため、強力なAI検出モデルの開発が求められる。

### データセット
本コンペのデータセットは Shutterstock と DeepMedia により提供され、以下の要素を含みます。
- **Shutterstock提供の本物の画像**（1/3は人が含まれる）
- **DeepMediaの最先端AIモデルが生成した対応画像**
- **リアルとAI画像のペアデータ**により、モデルの精度向上が可能

このデータセットを活用し、堅牢な画像識別モデルを構築することが本コンペの目的です。



## Vanilla Classificationとは？

本コンペで使用できる **「Vanilla Classification」** という技術を解説します。
Vanilla Classificationとは、特殊なテクニックやトリックを使わず、基本的な方法で画像分類を行うことを指します。すなわち、
- 一般的なCNN（またはViTなどのTransformer）を使用
- シンプルな前処理（リサイズ・正規化など）
- 標準的な学習アルゴリズム（クロスエントロピー損失、Adamなど）


このシンプルなアプローチを基に、どのようにモデルを設計し、改善できるかを考えるのが重要です。



## コードの解説　（データセット定義〜モデル作成のみ）
### 1. データセットの定義
```python
class CustomDataset(Dataset):
    def __init__(self, df, data_dir, transforms=None, is_train=True):
        """
        Args:
            df (pd.DataFrame): ファイル名とラベルの情報を持つDataFrame。
            data_dir (str): 画像ファイルが格納されているディレクトリ。
            transforms (albu.Compose, optional): 画像の前処理を適用する。
            is_train (bool, optional): 学習データか推論データかを識別。
        """
        self.df = df
        self.data_dir = data_dir
        self.transforms = transforms
        self.is_train = is_train

    def __len__(self):
        return len(self.df)
```
このクラスでは、DataFrame（CSVなどから読み込んだデータ）を用いて、画像ファイルとラベルを管理します。

### 2. モデルの選定：EfficientNetV2
```python
model = timm.create_model('tf_efficientnetv2_s.in21k_ft_in1k', 
                          pretrained=True,
                          num_classes=2)
```
ここでは、**EfficientNetV2** を選択しています。

#### **EfficientNetV2とは？**
EfficientNetV2は、Googleが提案したEfficientNetの改良版であり、
- **スケーリングの最適化**: モデルサイズや計算コストを抑えつつ高い精度を実現
- **プログレッシブラーニング**: 学習中にデータ解像度を徐々に増やす手法を活用
- **精度と速度のバランス**: モデルのパラメータ数を抑えながら高い精度を維持

本コンペでは、画像分類タスクのベースラインモデルとしてEfficientNetV2を採用しています。

### 3. 学習の実装
学習では、以下の要素を組み合わせています。
```python
optimizer = Adam(model.parameters(), lr=1e-5, weight_decay=1e-2)
scheduler = StepLR(optimizer, step_size=1, gamma=0.1)
loss_fn = nn.CrossEntropyLoss()
```
- **Adam**: 勾配降下法の最適化手法
- **StepLR**: 一定のエポックごとに学習率を減衰
- **CrossEntropyLoss**: クラス分類問題に適した損失関数

### 4. この後の流れ
本記事では、データセットの定義からモデルの作成までを解説しましたが、実際のコンペ参加では以下のような流れが続きます。

- データの前処理（Data Augmentation）
    - Albumentations を活用してデータ拡張を行い、モデルの汎化性能を向上。
- 学習・検証のループ
    - DataLoaderを用いたバッチ処理
    - 学習（Forward/Backward Propagation）
    - 検証データでの評価（Accuracy, F1-score など）
- ハイパーパラメータ調整
    - 学習率や重み減衰（weight decay）の調整
    - 学習率スケジューリング（LR Scheduler）
- 推論（Inference）
    - 学習済みモデルを用いてテストデータに対する予測を実行。
- アンサンブルや後処理
    - モデルの平均化や多数決アンサンブル
    - 予測結果の補正（Post-processing）

このように、モデルを作成した後は、データ拡張・学習・評価・推論・最適化といった一連のプロセスを繰り返しながら、精度を向上させていきます。


## 画像分類タスクにおいて「Vanilla Classification」が他のモデルより優れている理由

"Vanilla Classification"は、シンプルな基本的な分類アルゴリズムを指す場合が多いです。この場合、特定の複雑なアーキテクチャや追加の処理がない、基本的なモデルを指します。画像分類タスクにおいて「Vanilla Classification」が他のモデルより優れている理由としては、以下のようなポイントが考えられます：

### 1. **シンプルさと解釈可能性**
   - Vanilla Classificationはシンプルなモデル（例：線形分類器やシンプルなニューラルネットワーク）を使用するため、モデルの挙動や結果が解釈しやすいです。これにより、モデルの予測がどのように行われるかを追跡しやすく、実験的に理解しやすいという利点があります。

### 2. **オーバーフィッティングのリスク低減**
   - 複雑なモデルは過剰にデータに適合してしまい、オーバーフィッティングのリスクが高くなります。Vanilla Classificationはシンプルなので、適切な正則化や適切なパラメータの選択を行えば、オーバーフィッティングを抑えることができます。

### 3. **計算リソースの節約**
   - 他の複雑なモデル（例えば、畳み込みニューラルネットワークやトランスフォーマーなど）に比べて、Vanilla Classificationは計算リソースが少なくて済みます。特にデータ量が少ない場合や計算リソースが限られている場合、このシンプルなアプローチが有効です。

### 4. **汎用性の高さ**
   - Vanilla Classificationは、データセットに特化していないため、汎用的に他の画像分類タスクにも適用できる柔軟性があります。たとえば、画像の特徴量がシンプルである場合、複雑なモデルよりも良い結果が得られることがあります。

### 5. **トレーニング時間の短縮**
   - 複雑なアーキテクチャはトレーニングに長い時間がかかりますが、Vanilla Classificationは計算量が少なく、トレーニングが早いため、実験を迅速に繰り返してパラメータを調整することができます。

### 6. **基本的なパフォーマンス**
   - 複雑なモデルが必要ないシンプルなケース（例えば、画像の特徴が比較的単純である場合）では、Vanilla Classificationが他の高度なモデルと比べて遜色ない結果を出すことがあります。

### まとめ
Vanilla Classificationは、シンプルで計算効率が高く、解釈がしやすい点が強みです。特に、画像分類において非常に複雑なモデルを使う必要がない場合やリソースに制限がある場合に、効果的に動作することがあります。ただし、データセットが複雑で特徴が多様な場合には、CNNなどの高度な手法の方が優れた結果を得ることが一般的です。

今回は、KaggleでしようしVanilla Classificationを通じて、基本的な画像分類の実装と、EfficientNetV2の特徴を学ぶことができました。今後は、データ拡張やアンサンブル手法を試し、さらに精度を向上させていきたいと思います。

