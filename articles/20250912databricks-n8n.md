---
title: "Databricks DLTã§ãƒ¡ãƒ€ãƒªã‚ªãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰"
emoji: "ğŸŒ±"
type: "idea"
topics: ["databricks","ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆ","ãƒ¡ãƒ€ãƒªã‚ªãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£","zennfes2025free"]
published: true
publication_name: "headwaters"
---

# ã‚´ãƒ¼ãƒ«

## ç›®çš„

Delta Live Tableå†…ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€**Lakeflow å®£è¨€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** ã‚’ç”¨ã„ã¦ã€
UC Volumes ã‹ã‚‰ã®å–ã‚Šè¾¼ã¿ã€œé…ä¿¡ãƒ†ãƒ¼ãƒ–ãƒ«ç®¡ç†ã®åŸºæœ¬ã‚’æ´ã¿ã¾ã™ã€‚

:::message
è£œè¶³ï¼šæœ¬è¨˜äº‹ã¯ Unity CatalogãŒä½¿ç”¨ã§ãã‚‹å‰æ ã§ã™ã€‚ã‚«ã‚¿ãƒ­ã‚°/ã‚¹ã‚­ãƒ¼ãƒ/ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ä½œæˆãƒ»æ¨©é™ä»˜ä¸ãŒã§ãã‚‹ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ï¼†ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚
:::

## ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨

1. UC Volumes ã«ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãå‡ºã™
2. Auto Loader ã§å¢—åˆ†å–ã‚Šè¾¼ã¿ï¼ˆBronzeãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆï¼‰
3. å–ã‚Šè¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã«ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨ï¼ˆSilverãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆï¼‰
4. AUTO CDC ã§æœ€æ–°ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆåŒ–ã¨å±¥æ­´åŒ–ï¼ˆGoldãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆï¼‰

![](https://storage.googleapis.com/zenn-user-upload/909195733bf4-20250904.png)
*å®Œæˆã‚¤ãƒ¡ãƒ¼ã‚¸ï¼šå·¦ã‹ã‚‰Bronzeã€Silverã€GoldÃ—3*


### å‚è€ƒ

ã“ã¡ã‚‰ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’å‚è€ƒã«å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚

https://learn.microsoft.com/ja-jp/azure/databricks/dlt/tutorial-pipelines

# ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

## 0: ãƒ€ãƒŸâ€•ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹

ã¾ãšã¯ä»Šå›ä½¿ç”¨ã™ã‚‹ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™ã€‚
`faker` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã™ã®ã§ã€
æœ€åˆã®ã‚»ãƒ«ã§ `%pip install faker` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

:::details ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆç”¨ã‚³ãƒ¼ãƒ‰

```python
# äº‹å‰ã«ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å…¥ã‚Œã¦ãŠãã¨ç¢ºå®Ÿ
# %pip install faker

# ã‚«ã‚¿ãƒ­ã‚°/ã‚¹ã‚­ãƒ¼ãƒ/ãƒœãƒªãƒ¥ãƒ¼ãƒ åï¼ˆä»¥é™ã‚‚ãšã£ã¨åŒã˜åå‰ã‚’ä½¿ã„ã¾ã™ï¼‰
catalog = "workspace"
schema = dbName = db = "dbdemos_dlt_cdc"
volume_name = "raw_data"

spark.sql(f'CREATE CATALOG IF NOT EXISTS `{catalog}`')
spark.sql(f'USE CATALOG `{catalog}`')
spark.sql(f'CREATE SCHEMA IF NOT EXISTS `{catalog}`.`{schema}`')
spark.sql(f'USE SCHEMA `{schema}`')
spark.sql(f'CREATE VOLUME IF NOT EXISTS `{catalog}`.`{schema}`.`{volume_name}`')
volume_folder =  f"/Volumes/{catalog}/{db}/{volume_name}"

try:
  dbutils.fs.ls(volume_folder+"/customers")
except:
  print(f"folder doesn't exists, generating the data under {volume_folder}...")
  from pyspark.sql import functions as F
  from faker import Faker
  from collections import OrderedDict
  import uuid
  import random
  fake = Faker()

  fake_firstname = F.udf(fake.first_name)
  fake_lastname = F.udf(fake.last_name)
  fake_email = F.udf(fake.ascii_company_email)
  fake_date = F.udf(lambda:fake.date_time_this_month().strftime("%m-%d-%Y %H:%M:%S"))
  fake_address = F.udf(fake.address)
  operations = OrderedDict([("APPEND", 0.5),("DELETE", 0.1),("UPDATE", 0.3),(None, 0.01)])
  fake_operation = F.udf(lambda:fake.random_elements(elements=operations, length=1)[0])
  fake_id = F.udf(lambda: str(uuid.uuid4()) if random.uniform(0, 1) < 0.98 else None)

  df = spark.range(0, 100000).repartition(100)
  df = df.withColumn("id", fake_id())
  df = df.withColumn("firstname", fake_firstname())
  df = df.withColumn("lastname", fake_lastname())
  df = df.withColumn("email", fake_email())
  df = df.withColumn("address", fake_address())
  df = df.withColumn("operation", fake_operation())
  df_customers = df.withColumn("operation_date", fake_date())
  df_customers.repartition(100).write.format("json").mode("overwrite").save(volume_folder+"/customers")

```
:::
| address                                    | email                                                   | firstname   | id                                   | lastname | operation | operation\_date     |
| ------------------------------------------ | ------------------------------------------------------- | ----------- | ------------------------------------ | -------- | --------- | ------------------- |
| "5252 Margaret Key Suite 828\nMarybury..." | [skaufman@pierce.org](mailto:skaufman@pierce.org)       | Kimberly    | 6bef15f7-a9f8-4731-9ec3-34646cdfda0c | Norman   | UPDATE    | 09-03-2025 06:12:35 |
| "2483 Robert Camp Apt. 425\nSouth..."      | [ramosbrian@paul.biz](mailto:ramosbrian@paul.biz)       | Brittany    | e39a109c-d5b9-466e-8fb1-d4714d9e9808 | Garza    | DELETE    | 09-02-2025 17:01:58 |
| "0936 Phillips Turnpike\nBrianfort..."     | [urich@cook-fleming.com](mailto:urich@cook-fleming.com) | Christopher | 95a1...b1bd                          | Davis    | APPEND    | 09-01-2025 06:08:49 |

ã§ããŸãƒ†ãƒ¼ãƒ–ãƒ«å…ˆé ­3è¡Œã¯ã“ã‚“ãªæ„Ÿã˜ã€‚
ç”Ÿãƒ‡ãƒ¼ã‚¿ç›¸å½“ã®è³¼å…¥é¡§å®¢ãƒ†ãƒ¼ãƒ–ãƒ«ã¨æ€ã£ã¦ã„ãŸã ããŸã„ã§ã™ã€‚
ã“ã‚“ãªæ„Ÿã˜ã®è¡ŒãŒ10000è¡Œã‚ã‚Šã¾ã™ã€‚

## 1: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ

æ¬¡ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚

- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åï¼šä»»æ„ï¼ˆã“ã“ã§ã¯`0904-pipeline-test`ï¼‰
- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼šãƒˆãƒªã‚¬ãƒ¼ï¼ˆã¾ãšã¯æ‰‹å‹•å®Ÿè¡Œã§OKã€‚å¾Œã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å¤‰æ›´å¯ï¼‰
- å¤‰æ›å…ˆï¼ˆé…ä¿¡å…ˆï¼‰ï¼š0ã§ä½œæˆã—ãŸã‚«ã‚¿ãƒ­ã‚°/ã‚¹ã‚­ãƒ¼ãƒï¼ˆä¾‹ï¼šworkspace.dbÂ­demos_dlt_cdcï¼‰ ã‚’æŒ‡å®š
- ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ï¼šæœ¬è¨˜äº‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ç½®ã„ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’æŒ‡å®šï¼ˆä¾‹ï¼š/Users/ãƒ¦ãƒ¼ã‚¶ãƒ¼å/0904test/0904-pipeline-testï¼‰

![](https://storage.googleapis.com/zenn-user-upload/0fa2906edd53-20250904.png =500x)



## 2: è‡ªå‹•ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆï¼ˆBronzeï¼‰

ã“ã“ã§ã¯ **Auto Loaderï¼ˆè‡ªå‹•ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼‰** ã‚’ä½¿ã£ã¦ã€
ã‚¹ãƒ†ãƒƒãƒ—0ã§ä½œæˆã—ãŸ Volumesä¸Šã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã«å–ã‚Šè¾¼ã¿ã¾ã™ã€‚

ãƒ‡ãƒ¼ã‚¿åŸºç›¤ã®ä¸–ç•Œã§ã¯ã€ã“ã®ã‚ˆã†ã«å¤–éƒ¨ã‹ã‚‰å–ã‚Šè¾¼ã‚“ã ã€ŒåŠ å·¥å‰ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã€ã‚’ **Bronzeå±¤** ã¨å‘¼ã³ã¾ã™ã€‚
ç‰¹å¾´ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

- ç›®çš„ï¼šãƒ‡ãƒ¼ã‚¿ã‚’æ¬ æã‚„æ•´å½¢ã‚’ã›ãšã€ãã®ã¾ã¾å®‰å…¨ã«ä¿æŒã™ã‚‹
- åˆ©ç‚¹ï¼šå±¥æ­´ã‚’ãã®ã¾ã¾æ®‹ã›ã‚‹ãŸã‚ã€å¾Œã‹ã‚‰æ¤œè¨¼ã‚„å†å‡¦ç†ã«åˆ©ç”¨ã§ãã‚‹

Auto Loaderã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ç›£è¦–ã—ã€æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¿½åŠ ã•ã‚Œã‚‹ã¨è‡ªå‹•çš„ã«å–ã‚Šè¾¼ã‚“ã§ãã‚Œã‚‹ä»•çµ„ã¿ã§ã™ã€‚å¤§é‡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ç¶™ç¶šçš„ãªæ›´æ–°ã‚’æ‰±ã†å ´åˆã€å¾“æ¥ã®å˜ç´”ãª `read.json` ã‚ˆã‚ŠåŠ¹ç‡çš„ã‹ã¤å …ç‰¢ãªã®ãŒç‰¹å¾´ã§ã™ã€‚

ä»¥ä¸‹ã‚’ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«è¨˜è¿°ã—ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€
`customers_cdc_bronze` ã¨ã„ã† Bronzeãƒ†ãƒ¼ãƒ–ãƒ« ã«ãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Šè¾¼ã¾ã‚Œã¾ã™ã€‚

:::details `customers_cdc_bronze`ã®ä½œæˆ
```python
from dlt import *
from pyspark.sql.functions import *

# Bronze: ç”Ÿãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šè¾¼ã¿å…ˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
dlt.create_streaming_table(
  "customers_cdc_bronze",
  comment="New customer data incrementally ingested from cloud object storage landing zone"
)

# Auto Loader ã§ Volumes ã® JSON ã‚’èª­ã¿å–ã‚‹
@append_flow(
  target = "customers_cdc_bronze",
  name = "customers_bronze_ingest_flow"
)
def customers_bronze_ingest_flow():
  return (
      spark.readStream
          .format("cloudFiles")
          .option("cloudFiles.format", "json")
          .option("cloudFiles.inferColumnTypes", "true")
          # 0. ã®è¨­å®šã¨åˆã‚ã›ã‚‹
          .load("/Volumes/workspace/dbdemos_dlt_cdc/raw_data/customers")
  )

```
:::

![](https://storage.googleapis.com/zenn-user-upload/69e698aa6442-20250904.png =500x)
*ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã“ã‚“ãªæ„Ÿã˜ã§å‡¦ç†ãŒé€²ã‚€*

![](https://storage.googleapis.com/zenn-user-upload/770e44414525-20250904.png =500x)
*æˆåŠŸã—ãŸã‚‰ã“ã‚“ãªæ„Ÿã˜ã€‚ã¡ã‚‡ã£ã¨å…ˆã¾ã§ä½œã£ã¦ã„ã‚‹ã®ã¯ã‚¹ãƒ«ãƒ¼ã„ãŸã ã„ã¦*

![](https://storage.googleapis.com/zenn-user-upload/08ff86e6cea1-20250904.png =500x)
*ã‚¯ã‚¨ãƒªã§ç¢ºã‹ã‚ã‚‹ã¨ãƒ–ãƒ­ãƒ³ã‚ºã£ã½ã„ã¨ã‚ã‹ã‚‹*

ã“ã®æ®µéšã§ã¯ã¾ã ã€Œç”Ÿãƒ‡ãƒ¼ã‚¿ãã®ã¾ã¾ã€ã§ã€ä¸æ­£å€¤ã‚„æ¬ æã‚‚å«ã¾ã‚Œã¦ãŠã‚Šã€
**ã€Œãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾Deltaãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã—ãŸçŠ¶æ…‹ã€** ã§ã™ã€‚



## 3: ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆSilverï¼‰

æ¬¡ã¯ **Bronzeãƒ†ãƒ¼ãƒ–ãƒ«ã«å–ã‚Šè¾¼ã‚“ã ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã—ã¦ã€Silverãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ** ã—ã¾ã™ã€‚
ã“ã“ã§ã¯ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’å®ˆã‚‹ãŸã‚ã« **ã€ŒæœŸå¾…å€¤ï¼ˆExpectationsï¼‰ã€** ã‚’å®šç¾©ã—ã€æ¡ä»¶ã«åˆã‚ãªã„è¡Œã¯è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã™ã€‚
å…·ä½“çš„ã«ã¯æ¬¡ã®ãƒ«ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚

* **`ID`ãŒå­˜åœ¨ã™ã‚‹ã“ã¨**ï¼ˆ`id IS NOT NULL`ï¼‰
* **æ“ä½œã‚¿ã‚¤ãƒ—ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨**ï¼ˆ`APPEND / DELETE / UPDATE` ã®ã„ãšã‚Œã‹ï¼‰
* **JSONãŒæ­£ã—ãèª­ã¿å–ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨**ï¼ˆ`_rescued_data IS NULL`ï¼‰

ã“ã®å‡¦ç†ã«ã‚ˆã‚Šã€æ¬ æã‚„ä¸æ­£å€¤ã‚’å«ã‚“ã è¡Œã¯å‰Šé™¤ã•ã‚Œã€**CDCå‡¦ç†ã«è€ãˆã‚‰ã‚Œã‚‹ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ** ã«ãªã‚Šã¾ã™ã€‚
ã“ã“ã§ã€**ã€Œç”Ÿãƒ­ã‚°ï¼ˆBronzeï¼‰ã€ã‹ã‚‰ã€Œåˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ï¼ˆSilverï¼‰ã€ã«ãªã‚‹** ã¨ã„ã†ã“ã¨ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€`customers_cdc_clean` ãŒä½œæˆã•ã‚Œã¾ã™ã€‚

:::details `customers_cdc_clean`ã®ä½œæˆ
```python
dlt.create_streaming_table(
  name = "customers_cdc_clean",
  expect_all_or_drop = {
    "no_rescued_data": "_rescued_data IS NULL",
    "valid_id": "id IS NOT NULL",
    "valid_operation": "operation IN ('APPEND', 'DELETE', 'UPDATE')"
  }
)

@append_flow(
  target = "customers_cdc_clean",
  name = "customers_cdc_clean_flow"
)
def customers_cdc_clean_flow():
  return (
      dlt.read_stream("customers_cdc_bronze")
          .select("address", "email", "id", "firstname", "lastname", "operation", "operation_date", "_rescued_data")
  )
```
:::

![](https://storage.googleapis.com/zenn-user-upload/b0f657805a89-20250904.png =500x)
*ãƒ–ãƒ­ãƒ³ã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã¯10000ã‚ã£ãŸãŒâ€¦*

![](https://storage.googleapis.com/zenn-user-upload/e81898d652e5-20250904.png =500x)
*ã‚·ãƒ«ãƒãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãªã‚‹éç¨‹ã§3000ãã‚‰ã„é™¤ã‹ã‚ŒãŸ*


## 4: `AUTO CDC`ã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡ºï¼ˆGold-1ï¼‰

ã“ã“ã§ã¯ã€**æœ€æ–°çŠ¶æ…‹ã®é¡§å®¢ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆcustomersï¼‰** ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
CDCãƒ‡ãƒ¼ã‚¿ã«ã¯ã€Œè¿½åŠ ï¼ˆAPPENDï¼‰ã€ã€Œæ›´æ–°ï¼ˆUPDATEï¼‰ã€ã€Œå‰Šé™¤ï¼ˆDELETEï¼‰ã€ãŒæ··åœ¨ã—ã¦ã„ã‚‹ãŸã‚ã€
å˜ç´”ã«å–ã‚Šè¾¼ã‚€ã ã‘ã§ã¯ **é‡è¤‡ã‚„å¤ã„å€¤ãŒæ®‹ã£ã¦ã—ã¾ã†** ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã‚Œã‚’ä½¿ã„ã‚„ã™ãã™ã‚‹ãŸã‚ã«åˆ©ç”¨ã™ã‚‹ã®ãŒ **AUTO CDC ãƒ•ãƒ­ãƒ¼** ã§ã™ã€‚
AUTO CDC ã¯ã€Databricksã®æ©Ÿèƒ½ã®ã²ã¨ã¤ã§ã€
**Change Data Captureï¼ˆCDCï¼šå¤‰æ›´ãƒ‡ãƒ¼ã‚¿æ•æ‰ï¼‰ã‚’è‡ªå‹•å‡¦ç†ã™ã‚‹ä»•çµ„ã¿** ã§ã™ã€‚
Databricks Lakeflow å®£è¨€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã¾ã‚Œã¦ãŠã‚Šã€
ä»¥ä¸‹ã®ã‚ˆã†ãªã“ã¨ã‚’è‡ªå‹•ã§è¡Œã£ã¦ãã‚Œã¾ã™ã€‚

* ä¸»ã‚­ãƒ¼ï¼ˆã“ã“ã§ã¯ `id`ï¼‰ã‚’åŸºæº–ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ç…§åˆ
* `operation_date` ã‚’ä½¿ã£ã¦æœ€æ–°ã®è¡Œã‚’ç‰¹å®š
* `DELETE` æŒ‡å®šã•ã‚ŒãŸè¡Œã‚’é™¤å»

çµæœã¨ã—ã¦ã€`customers` ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯ã€Œå¸¸ã«æœ€æ–°ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã€ãŒä¿æŒã•ã‚Œã¾ã™ã€‚
ã¤ã¾ã‚Šã€**ã€ŒSilverã®CDCãƒ‡ãƒ¼ã‚¿ â†’ æœ€æ–°ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã€** ã¨ã„ã†å¤‰æ›ã‚’æ‹…ã†ã®ãŒã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã™ã€‚

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€`customers` ã¨ã„ã†ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ãŒä½œæˆã•ã‚Œã¾ã™ã€‚

:::details `customers`ã®ä½œæˆ
```python
dlt.create_streaming_table(name="customers", comment="Clean, materialized customers")

dlt.create_auto_cdc_flow(
  target="customers",                   # ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºå…ˆï¼ˆæœ€æ–°ã®é¡§å®¢ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰
  source="customers_cdc_clean",         # å…¥åŠ›ï¼ˆã‚¯ãƒªãƒ¼ãƒ³æ¸ˆã¿CDCãƒ‡ãƒ¼ã‚¿ï¼‰
  keys=["id"],                          # ä¸»ã‚­ãƒ¼ã§ãƒãƒƒãƒãƒ³ã‚°
  sequence_by=col("operation_date"),    # operation_dateã§æœ€æ–°ã‚’åˆ¤å®š
  ignore_null_updates=False,
  apply_as_deletes=expr("operation = 'DELETE'"),  # DELETEæ“ä½œã‚’å‰Šé™¤ã¨ã—ã¦é©ç”¨
  except_column_list=["operation", "operation_date", "_rescued_data"],
)
```
:::

ã§ããŸ`customers`ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ã“ã‚“ãªæ„Ÿã˜ã€‚

![](https://storage.googleapis.com/zenn-user-upload/b84a7e460db2-20250904.png =500x)

![](https://storage.googleapis.com/zenn-user-upload/4030e57484b6-20250904.png =500x)
*åŒã˜é¡§å®¢ã®é‡è¤‡åˆ†ãŒé™¤ã‹ã‚ŒãŸã®ã§ã€ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚‚æ¸›ã£ã¦ã„ã‚‹*


Silverãƒ†ãƒ¼ãƒ–ãƒ«ã¾ã§ã¯è¤‡æ•°è³¼å…¥ã—ã¦ã„ã‚‹é¡§å®¢IDã«å¯¾ã—ã¦ã¯è¤‡æ•°ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒæ··åœ¨ã—ã¦ã„ã¾ã—ãŸãŒã€
ã“ã®ä½œæ¥­ã«ã‚ˆã‚Šæœ€æ–°ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿ã«ãªã‚Šã¾ã—ãŸã€‚



## 5: `SCD Type 2` ã§å…¨ã¦ã®å¤‰æ›´å±¥æ­´ã‚’ä¿æŒï¼ˆGold-2ï¼‰

æ¬¡ã«2ã¤ç›®ã®Goldãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦ã€ **ã™ã¹ã¦ã®å¤‰æ›´ï¼ˆAPPEND / UPDATE / DELETEï¼‰ã‚’å±¥æ­´ã¨ã—ã¦ä¿å­˜ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«** ã‚’ä½œæˆã—ã¾ã™ã€‚
AUTO CDC ã® **`stored_as_scd_type="2"`** ã‚’æŒ‡å®šã™ã‚‹ã¨ã€ä»¥ä¸‹ã‚’è‡ªå‹•ã§å‡¦ç†ã—ã¦ãã‚Œã¾ã™ã€‚

- ä¸»ã‚­ãƒ¼ã”ã¨ã« **æœ‰åŠ¹æœŸé–“ï¼ˆé–‹å§‹ãƒ»çµ‚äº†æ™‚åˆ»ï¼‰** ã‚’ä»˜ä¸
- **ç¾åœ¨ãƒ•ãƒ©ã‚°** ã‚’ä»˜ä¸ã—ã€Œä»Šã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã€ã‹ã©ã†ã‹ã‚’åˆ¤åˆ¥
- `sequence_by` ã®æ™‚ç³»åˆ—ã«åŸºã¥ãã€**é †åºãŒä¹±ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã‚‚æ­£ã—ãæ•´ç†**

ã“ã“ã§ã„ã†å¤‰æ›´å±¥æ­´ã¨ã¯ã€**é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãŒæ™‚é–“ã¨ã¨ã‚‚ã«ã©ã†å¤‰ã‚ã£ãŸã‹** ã‚’ä¸€ä»¶ãšã¤è¨˜éŒ²ã—ãŸã‚‚ã®ã§ã™ã€‚å±¥æ­´ã‚’ä¿æŒã™ã‚‹ã“ã¨ã§ã€æ¬¡ã®ã‚ˆã†ãªåˆ†æã‚„ç¢ºèªãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

* **ç‰¹å®šã®é¡§å®¢ã®å±¥æ­´ã‚’è¿½è·¡**
  ä¾‹ï¼šã€Œã“ã®é¡§å®¢ã¯ã„ã¤ä½æ‰€ãŒå¤‰æ›´ã•ã‚ŒãŸã®ã‹ï¼Ÿã€
  
* **ä»»æ„ã®æ™‚ç‚¹ã®çŠ¶æ…‹ã‚’å†ç¾**
  ä¾‹ï¼šã€Œ2025-09-02 æ™‚ç‚¹ã§ã¯ã“ã®é¡§å®¢ã®ä½æ‰€ã¯ä½•ã ã£ãŸã‹ï¼Ÿã€
  
* **è¤‡æ•°ã®æ™‚ç‚¹ã‚’æ¨ªä¸¦ã³ã§æ¯”è¼ƒ**
  ä¾‹ï¼šã€Œ2023å¹´ã¨2024å¹´ã§ã“ã®é¡§å®¢ã®ä½æ‰€ã¯ã©ã†é•ã£ã¦ã„ãŸã‹ï¼Ÿã€

:::details `customers_history`ã®ä½œæˆ
```python
# å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆSCD2ï¼‰ã‚’ä½œæˆ
dlt.create_streaming_table(
    name="customers_history",
    comment="Slowly Changing Dimension Type 2 for customers"
)

# ã™ã¹ã¦ã®å¤‰æ›´ã‚’SCD2ã¨ã—ã¦ä¿å­˜
dlt.create_auto_cdc_flow(
    target="customers_history",
    source="customers_cdc_clean",
    keys=["id"],                              # å¤‰æ›´è¿½è·¡ã®ä¸»ã‚­ãƒ¼
    sequence_by=col("operation_ts"),          # æ™‚ç³»åˆ—æ•´åˆï¼ˆã‚¹ãƒ†ãƒƒãƒ—â‘¢ã§ä½œæˆï¼‰
    ignore_null_updates=False,
    apply_as_deletes=expr("operation = 'DELETE'"),
    except_column_list=["operation", "operation_date", "_rescued_data", "operation_ts"],
    stored_as_scd_type="2",                   # SCD Type 2 ã‚’æœ‰åŠ¹åŒ–
)  # ä»¥å¾Œã€é–‹å§‹/çµ‚äº†æ™‚åˆ»ã‚„ç¾åœ¨ãƒ•ãƒ©ã‚°ãªã©ã‚’è‡ªå‹•ç®¡ç†
```
:::

ã€Œ2025-09-02 12æ™‚ã«ã€ã©ã®é¡§å®¢ãŒã©ã®ä½æ‰€ã‚’æŒã£ã¦ã„ãŸã‹ã€ã‚’è¡¨ç¤ºã•ã›ã‚‹ã¨ã“ã‚“ãªæ„Ÿã˜ã§ã™ã€‚


![](https://storage.googleapis.com/zenn-user-upload/e528989fc8cd-20250904.png =500x)

## 6: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®å¤‰æ›´å›æ•°ã‚’é›†è¨ˆï¼ˆGold-3ï¼‰

`customers_history` ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯ã€å„é¡§å®¢ãŒè‡ªåˆ†ã®æƒ…å ±ã«åŠ ãˆãŸã™ã¹ã¦ã®å¤‰æ›´å±¥æ­´ãŒå«ã¾ã‚Œã¦ã„ã¾ã—ãŸãŒã€æœ€å¾Œã«ãã‚Œã‚’é›†è¨ˆã—ã¦ã€
**ã©ã®é¡§å®¢ãŒã©ã®é …ç›®ã‚’ä½•å›å¤‰æ›´ã—ãŸã‹** ã‚’å¯è¦–åŒ–ã™ã‚‹ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚

ä»¥ä¸‹ã®ã‚ˆã†ãªã‚·ãƒŠãƒªã‚ªã§å½¹ç«‹ã¡ã¾ã™ã€‚

* **ä¸æ­£è¡Œç‚ºã®æ¤œå‡º**ï¼šç‰¹å®šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã ã‘ãŒç•°å¸¸ã«é »ç¹ã«æƒ…å ±ã‚’å¤‰æ›´ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
* **ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**ï¼šå…¥åŠ›é …ç›®ã®å¤‰åŒ–ãŒå¤šã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦ã€æ”¹å–„ææ¡ˆã‚„æ¨å¥¨è¨­å®šã‚’æç¤º
* **ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ**ï¼šã©ã®é …ç›®ãŒé »ç¹ã«å¤‰ã‚ã£ã¦ã„ã‚‹ã‹ã‚’æŠŠæ¡ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã‚„å…¥åŠ›UIã®æ”¹å–„ã«ã¤ãªã’ã‚‹

SCD2ã‚’é©ç”¨ã—ãŸ `customers_history` ã§ã¯é‡è¤‡ãŒã™ã§ã«æ•´ç†ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€
**ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã”ã¨ã«ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã ã‘ã§ç°¡å˜ã«é›†è¨ˆ**ã§ãã¾ã™ã€‚

:::details é›†è¨ˆãƒ“ãƒ¥ãƒ¼ã®ä½œæˆã‚³ãƒ¼ãƒ‰

```python
@dlt.table(
  name = "customers_history_agg",
  comment = "Aggregated customer history"
)
def customers_history_agg():
  return (
    dlt.read("customers_history")
      .groupBy("id")
      .agg(
          count("address").alias("address_count"),
          count("email").alias("email_count"),
          count("firstname").alias("firstname_count"),
          count("lastname").alias("lastname_count")
      )
  )
```

:::


# ã¾ã¨ã‚

ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šè¾¼ã¿ã‹ã‚‰ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã€æœ€æ–°åŒ–ã€å±¥æ­´ç®¡ç†ã€é›†è¨ˆã¾ã§ã‚’è‡ªå‹•åŒ–ã—ãŸåŸºæœ¬çš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½“é¨“ã—ã¾ã—ãŸã€‚
Engineer Associateã®è³‡æ ¼ã§å­¦ã‚“ã ç¯„å›²ã§ã‚‚ã‚ã‚‹ã®ã§ã™ãŒã€ã‚„ã¯ã‚Šæ‰‹ã‚’å‹•ã‹ã™ã¨ã‚ã‹ã‚‹ã“ã¨ã‚‚å¤šã„ã¨æ€ã„ã¾ã™ã€‚

æœ¬å½“ã¯ã‚¸ãƒ§ãƒ–ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãªã©ã‚‚ã—ã‚ˆã†ã¨ã—ãŸã®ã§ã™ãŒã€ä»Šå›ã¯ã¡ã‚‡ã£ã¨æ–‡ç« ãŒé•·ããªã‚ŠéããŸã®ã§æ¬¡å›ä»¥é™ã«ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚


